import os
import datetime
import feedparser
import requests
import json
import time

# --- è¨­å®š ---
API_KEY = os.environ["GEMINI_API_KEY"]
# ç¢ºå®Ÿã«å­˜åœ¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«åã¨APIãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®š
API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={API_KEY}"

POSTS_DIR = "src/pages/posts"
os.makedirs(POSTS_DIR, exist_ok=True)

RSS_URLS = [
    "https://www.thestar.com.my/rss/news/nation",
    "https://www.thestar.com.my/rss/metro/community"
]

def ask_ai(title, summary, link):
    print(f"AIç¿»è¨³ä¸­: {title}")
    
    prompt = f"""
    ã‚ãªãŸã¯ãƒšãƒŠãƒ³åœ¨ä½æ—¥æœ¬äººå‘ã‘ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ç·¨é›†é•·ã§ã™ã€‚
    ä»¥ä¸‹ã®è‹±èªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ã€å­è‚²ã¦ä¸–å¸¯ã‚„æ¯å­ç•™å­¦ç”ŸãŒèª­ã¿ã‚„ã™ã„æ—¥æœ¬èªã«å…¨æ–‡ç¿»è¨³ãƒ»æ•´å½¢ã—ã¦ãã ã•ã„ã€‚

    ã‚¿ã‚¤ãƒˆãƒ«: {title}
    å†…å®¹: {summary}

    ã€å‡ºåŠ›ãƒ«ãƒ¼ãƒ«ã€‘
    1. å†’é ­ã«ã€Œã‚¸ãƒ£ãƒ³ãƒ«ï¼šã€‡ã€‡ã€ã‚’æ˜è¨˜
    2. ã‚¿ã‚¤ãƒˆãƒ«ã¯ã€Œã€ã‚¸ãƒ£ãƒ³ãƒ«ã€‘ã‚¿ã‚¤ãƒˆãƒ«ã€ã®å½¢å¼ã«ã€‚
    3. æœ¬æ–‡ã¯3-4è¡Œã”ã¨ã«æ”¹è¡Œã‚’å…¥ã‚Œã€èª­ã¿ã‚„ã™ãã€‚
    4. æœ€å¾Œã«ã€ŒğŸ”— å‚ç…§å…ƒè¨˜äº‹ã‚’ç¢ºèªã™ã‚‹ã€ã¨ã„ã†ãƒªãƒ³ã‚¯ã‚’ã¤ã‘ã‚‹ã€‚
    5. å‡ºåŠ›ã¯ä»¥ä¸‹ã®Markdownå½¢å¼ã§ã€‚
    ---
    title: "ã€ã‚¸ãƒ£ãƒ³ãƒ«ã€‘ã‚¿ã‚¤ãƒˆãƒ«"
    date: "{datetime.date.today()}"
    category: "ãƒ‹ãƒ¥ãƒ¼ã‚¹"
    ---
    <div class="genre-label">ã‚¸ãƒ£ãƒ³ãƒ«ï¼šãƒ‹ãƒ¥ãƒ¼ã‚¹</div>
    <h3>ã€å†…å®¹ï¼ˆå…¨æ–‡ç¿»è¨³ï¼‰ã€‘</h3>
    """

    payload = {
        "contents": [{
            "parts": [{"text": prompt}]
        }]
    }
    headers = {'Content-Type': 'application/json'}

    try:
        response = requests.post(API_URL, headers=headers, data=json.dumps(payload))
        data = response.json()
        
        # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
        if "candidates" in data:
            return data["candidates"][0]["content"]["parts"][0]["text"]
        else:
            print(f"APIã‚¨ãƒ©ãƒ¼: {data}")
            return None
    except Exception as e:
        print(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return None

# --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
print("ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—é–‹å§‹...")
articles_count = 0

for url in RSS_URLS:
    feed = feedparser.parse(url)
    print(f"ã‚½ãƒ¼ã‚¹å–å¾—: {url} (è¨˜äº‹æ•°: {len(feed.entries)})")
    
    for entry in feed.entries[:5]: 
        if articles_count >= 10: break
        
        clean_title = "".join([c for c in entry.title if c.isalnum() or c==' '])[:30].strip().replace(" ", "_")
        filename = os.path.join(POSTS_DIR, f"{datetime.date.today()}-{clean_title}.md")
        
        if os.path.exists(filename): continue

        article_md = ask_ai(entry.title, entry.summary, entry.link)
        
        if article_md:
            with open(filename, "w", encoding="utf-8") as f:
                f.write(article_md)
            print(f"ä¿å­˜å®Œäº†: {filename}")
            articles_count += 1
        
        time.sleep(2)

print(f"æœ¬æ—¥ã®æ¥­å‹™çµ‚äº†ã€‚ä½œæˆè¨˜äº‹æ•°: {articles_count}")
